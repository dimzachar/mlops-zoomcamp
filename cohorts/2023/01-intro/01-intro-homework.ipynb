{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15ff897f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8816e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataframe(filename):\n",
    "    \"\"\"\n",
    "    Reads a dataframe from a file and performs initial preprocessing.\n",
    "\n",
    "    Args:\n",
    "        filename (str): The path to the file to read.\n",
    "\n",
    "    Returns:\n",
    "        df (DataFrame): The preprocessed dataframe.\n",
    "    \"\"\"\n",
    "    \n",
    "    num_records = None\n",
    "\n",
    "    try:\n",
    "        # Check the file extension and read the file accordingly\n",
    "        if filename.endswith('.csv'):\n",
    "            df = pd.read_csv(filename)\n",
    "            # Convert columns to datetime\n",
    "            df.tpep_dropoff_datetime = pd.to_datetime(df.tpep_dropoff_datetime)\n",
    "            df.tpep_pickup_datetime = pd.to_datetime(df.tpep_pickup_datetime)\n",
    "        elif filename.endswith('.parquet'):\n",
    "            df = pd.read_parquet(filename)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file: {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "    \n",
    "    num_columns = df.shape[1]\n",
    "    num_records_before = df.shape[0]\n",
    "    \n",
    "    # Calculate trip duration in minutes\n",
    "    df['duration'] = (df['tpep_dropoff_datetime'] - df['tpep_pickup_datetime']).dt.total_seconds() / 60\n",
    "    std_duration = df['duration'].std()\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    # Filter out records with duration less than 1 minute or more than 60 minutes\n",
    "    df = df[(df['duration'] >= 1) & (df['duration'] <= 60)].copy()\n",
    "\n",
    "    num_records_after = df.shape[0]\n",
    "    records_dropped = num_records_before - num_records_after\n",
    "\n",
    "    # Calculate fraction of records remaining\n",
    "    fraction_remaining = num_records_after / num_records_before\n",
    "\n",
    "    \n",
    "        # Extract month from filename\n",
    "    month = filename.split('_')[-1].split('.')[0]\n",
    "    if month == '2022-01':\n",
    "        print(f'The dataframe has {num_columns} columns.')\n",
    "        print(f'Standard deviation of duration for January: {std_duration} minutes')\n",
    "        print(f'Number of records before: {num_records_before}')\n",
    "        print(f'Number of records after: {num_records_after}')\n",
    "        print(f'Number of records dropped: {records_dropped}')\n",
    "        print(f'Fraction of records left after dropping outliers: {fraction_remaining:.2%}')\n",
    "        \n",
    "        \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afbcb091",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(df_train, df_val, categorical, target):\n",
    "    \"\"\"\n",
    "    Function to train the model and calculate RMSE for train and validation sets.\n",
    "\n",
    "    Args:\n",
    "        df_train (DataFrame): The training data.\n",
    "        df_val (DataFrame): The validation data.\n",
    "        categorical (list): List of categorical features.\n",
    "        target (str): The target variable.\n",
    "\n",
    "    Returns:\n",
    "        dv (DictVectorizer): The fitted DictVectorizer.\n",
    "        lr (LinearRegression): The trained linear regression model.\n",
    "        rmse_train (float): RMSE for the training set.\n",
    "        rmse_val (float): RMSE for the validation set.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize DictVectorizer\n",
    "    dv = DictVectorizer()\n",
    "    \n",
    "    # Transform the dataframe into a list of dictionaries\n",
    "    train_dicts = df_train[categorical].to_dict(orient='records')\n",
    "    \n",
    "    # Fit and transform the data\n",
    "    X_train = dv.fit_transform(train_dicts)\n",
    "    \n",
    "    # The dimensionality of this matrix is the number of columns in X_train\n",
    "    dimensionality = X_train.shape[1]\n",
    "    print(f'The dimensionality of the matrix is {dimensionality}')\n",
    "    print(len(dv.feature_names_))\n",
    "\n",
    "    # Transform the validation dataframe into a list of dictionaries\n",
    "    val_dicts = df_val[categorical].to_dict(orient='records')\n",
    "    \n",
    "    # Transform the validation data to a feature matrix using the same DictVectorizer\n",
    "    X_val = dv.transform(val_dicts)\n",
    "\n",
    "    # Get the target values for the training and validation data\n",
    "    y_train = df_train[target].values\n",
    "    y_val = df_val[target].values\n",
    "\n",
    "    # Initialize a linear regression model\n",
    "    lr = LinearRegression()\n",
    "    \n",
    "    # Train the model on the training data\n",
    "    lr.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the training and validation data\n",
    "    y_pred_train = lr.predict(X_train)\n",
    "    y_pred_val = lr.predict(X_val)\n",
    "\n",
    "    # Calculate the root mean square error of the predictions on the training and validation data\n",
    "    rmse_train = mean_squared_error(y_train, y_pred_train, squared=False)\n",
    "    rmse_val = mean_squared_error(y_val, y_pred_val, squared=False)\n",
    "    \n",
    "    print(f'Training RMSE: {rmse_train}')\n",
    "    print(f'Validation RMSE: {rmse_val}')\n",
    "\n",
    "    return dv, lr, rmse_train, rmse_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bfc8e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(dv, model, model_path):\n",
    "    \"\"\"\n",
    "    Function to save the model.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(os.path.dirname(model_path)):\n",
    "        os.makedirs(os.path.dirname(model_path))\n",
    "\n",
    "    with open(model_path, 'wb') as f_out:\n",
    "        joblib.dump((dv, model), f_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27d7cbdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataframe has 19 columns.\n",
      "Standard deviation of duration for January: 46.44530513776499 minutes\n",
      "Number of records before: 2463931\n",
      "Number of records after: 2421440\n",
      "Number of records dropped: 42491\n",
      "Fraction of records left after dropping outliers: 98.28%\n"
     ]
    }
   ],
   "source": [
    "df_train = read_dataframe('~/anaconda3/envs/project/mlops-zoomcamp/data/yellow_tripdata_2022-01.parquet')\n",
    "df_val = read_dataframe('~/anaconda3/envs/project/mlops-zoomcamp/data/yellow_tripdata_2022-02.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88cbd3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimensionality of the matrix is 2\n",
      "2\n",
      "Training RMSE: 8.920327827581444\n",
      "Validation RMSE: 9.638272212087236\n"
     ]
    }
   ],
   "source": [
    "categorical = ['PULocationID', 'DOLocationID']\n",
    "target = 'duration'\n",
    "\n",
    "dv, model, rmse_train, rmse_val = train_model(df_train, df_val, categorical, target)\n",
    "\n",
    "# save_model(dv, model, 'models/lin_reg.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a49eb4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
